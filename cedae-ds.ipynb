{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "447d8a86",
   "metadata": {},
   "source": [
    "# Data Science applied to CEDAE data\n",
    "\n",
    "<img src=\"cedae-logo.png\" align=\"right\" width=\"200\" style=\"margin: 20px; 20px\"/>\n",
    "\n",
    "CEDAE is the coorporation that provides drinking water and wastewater services for the city of Rio de Janeiro.\n",
    "They provide plenty of data for the press and for the population, due to a law imposed by the Ministry of Health of Brazil.\n",
    "\n",
    "There is data for physical, chemical and biological parameters of the drinking water of all ETAs (Estações de Tratamento de Água, or _Water Treatment Stations_).\n",
    "In specific, the Guandu is the largest ETA of the world, providing drinking water for the municipalities of Nilópolis, Nova Iguaçu, Duque de Caxias, Belford Roxo, São João de Meriti, Itaguaí, Queimados and Rio de Janeiro.\n",
    "\n",
    "The data is in PDF form. We would like to convert this PDF into CSV so that we can vizualize it better in [Tableau](https://www.tableau.com/). First, we are interested to download the PDFs relating to geosmin (geosmina, in Portuguese). Links to them are available in the following public web page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ccb167c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CEDAE_page_URL = 'https://cedae.com.br/relatoriosguandu'\n",
    "CEDAE_page_encoding = 'utf8'\n",
    "CEDAE_page_keywords = ['GEOSMINA']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97685b15",
   "metadata": {},
   "source": [
    "We download the HTML page with the `urllib` module. The `urllib.request.urlopen` returns a file pointer, which yields a stream of bytes, which is then decoded to a UTF-8 string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8c2cde5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting 'https://cedae.com.br/relatoriosguandu'\n",
      "Decoding HTML to 'utf8' encoding\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "print('Requesting \\'%s\\'' % CEDAE_page_URL)\n",
    "with urllib.request.urlopen(CEDAE_page_URL) as fp:\n",
    "    CEDAE_data_bytes = fp.read()\n",
    "    print('Decoding HTML to \\'%s\\' encoding' % CEDAE_page_encoding)\n",
    "    CEDAE_data_Unicode = CEDAE_data_bytes.decode(CEDAE_page_encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b3fb67",
   "metadata": {},
   "source": [
    "For scrapping links to PDFs relating to geosmin, we inherit from the `HTMLParser` class from the `html.parser` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5340e059",
   "metadata": {},
   "outputs": [],
   "source": [
    "import html.parser\n",
    "\n",
    "class URLScrapper(html.parser.HTMLParser):\n",
    "    def __init__(self, keywords):\n",
    "        super().__init__()\n",
    "        self.URL = None\n",
    "        self.URLs = []\n",
    "        self.keywords = keywords\n",
    "\n",
    "    def get_URLs(self):\n",
    "        return self.URLs\n",
    "\n",
    "    def handle_starttag(self, tag, attrs):\n",
    "        if tag == 'a':\n",
    "            for name, value in attrs:\n",
    "                if name == 'href':\n",
    "                    self.URL = value\n",
    "                    break\n",
    "\n",
    "    def handle_data(self, data):\n",
    "        if self.URL is not None:\n",
    "            for keyword in self.keywords:\n",
    "                if keyword in data:\n",
    "                    self.URLs.append(self.URL)\n",
    "                    break\n",
    "\n",
    "    def handle_endtag(self, tag):\n",
    "        if tag == 'a':\n",
    "            self.URL = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bd4670",
   "metadata": {},
   "source": [
    "We then feed the parser with the HTML page contents and get the scrapped URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb6592eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scrapping URLs from HTML\n",
      "2 URLs scrapped\n"
     ]
    }
   ],
   "source": [
    "scrapper = URLScrapper(CEDAE_page_keywords)\n",
    "print('Scrapping URLs from HTML')\n",
    "scrapper.feed(CEDAE_data_Unicode)\n",
    "scrapped_URLs = scrapper.get_URLs()\n",
    "print('%d URLs scrapped' % len(scrapped_URLs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c21b5a0",
   "metadata": {},
   "source": [
    "We create a directory for storing the PDFs (and really don't care if it already exists)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92b4ca77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "try:\n",
    "    os.mkdir('data')\n",
    "except FileExistsError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e3bd94",
   "metadata": {},
   "source": [
    "Now we iterate through the URLs, downloading each file and storing in the recently created directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d77c6fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting 'https://storage.googleapis.com/site-cedae/Qualidade_da_Agua/RelatorioGuandu/2021/RESULTADOS%20GEOSMINA%20-%20MIB%20-%20%2020210504.pdf'\n",
      "Writing to 'data/RESULTADOS GEOSMINA - MIB -  20210504.pdf'\n",
      "Requesting 'https://storage.googleapis.com/site-cedae/Qualidade_da_Agua/RelatorioGuandu/RESULTADOS%20GEOSMINA%20-%20MIB%20-%20%202020.pdf'\n",
      "Writing to 'data/RESULTADOS GEOSMINA - MIB -  2020.pdf'\n"
     ]
    }
   ],
   "source": [
    "import urllib.parse\n",
    "\n",
    "for scrapped_URL in scrapped_URLs:\n",
    "    scrapped_URL = scrapped_URL.replace(' ', '%20')\n",
    "    print('Requesting \\'%s\\'' % scrapped_URL)\n",
    "    with urllib.request.urlopen(scrapped_URL) as infp:\n",
    "        parsed_URL = urllib.parse.urlparse(scrapped_URL)\n",
    "        filename = os.path.basename(parsed_URL.path).replace('%20', ' ')\n",
    "        filepath = os.path.join('data', filename)\n",
    "        print('Writing to \\'%s\\'' % filepath)\n",
    "        with open(filepath, 'wb') as outfp:\n",
    "            outfp.write(infp.read())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
